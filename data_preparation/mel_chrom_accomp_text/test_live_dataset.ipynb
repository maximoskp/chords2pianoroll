{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypianoroll\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import io\n",
    "import symusic\n",
    "from pathlib import Path\n",
    "\n",
    "from chroma_subsystem.BinaryTokenizer import BinaryTokenizer, SimpleSerialChromaTokenizer\n",
    "from miditok import REMI, TokenizerConfig\n",
    "from transformers import RobertaTokenizer, RobertaTokenizerFast, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LiveMelCATDataset(Dataset):\n",
    "    def __init__(self, midis_folder, segment_size=64, resolution=24):\n",
    "        self.midis_folder = midis_folder\n",
    "        self.midis_list = os.listdir(midis_folder)\n",
    "        self.segment_size = segment_size\n",
    "        self.resolution = resolution\n",
    "        self.binary_chroma_tokenizer = SimpleSerialChromaTokenizer()\n",
    "        self.remi_tokenizer = REMI(params=Path('/media/datadisk/data/pretrained_models/midis_REMI_BPE_tokenizer.json'))\n",
    "        self.roberta_tokenizer_chroma = RobertaTokenizerFast.from_pretrained('/media/datadisk/data/pretrained_models/chroma_mlm_tiny/chroma_wordlevel_tokenizer')\n",
    "        self.roberta_tokenizer_midi = RobertaTokenizerFast.from_pretrained('/media/datadisk/data/pretrained_models/midi_mlm_tiny/midi_wordlevel_tokenizer')\n",
    "        self.roberta_tokenizer_text = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "    # end init\n",
    "    def __len__(self):\n",
    "        return len(self.midis_list)\n",
    "    # end len\n",
    "    def __getitem__(self, idx):\n",
    "        print('idx:', idx)\n",
    "        print(self.midis_list[idx])\n",
    "        # load a midi file in pianoroll\n",
    "        main_piece = pypianoroll.read(self.midis_folder + os.sep + self.midis_list[idx], resolution=self.resolution)\n",
    "        main_piece_size = main_piece.downbeat.shape[0]\n",
    "        # make deepcopy\n",
    "        new_piece = deepcopy(main_piece)\n",
    "        # trim piece\n",
    "        start_idx = np.random.randint( main_piece_size - self.segment_size*main_piece.resolution )\n",
    "        end_idx = start_idx + self.segment_size*main_piece.resolution\n",
    "        new_piece.trim(start_idx, end_idx)\n",
    "        # split melody - accompaniment\n",
    "        melody_piece, accomp_piece = self.split_melody_accompaniment( new_piece )\n",
    "        # keep chroma from accompaniment\n",
    "        chroma_zoomed_out = self.chroma_from_pianoroll(accomp_piece)\n",
    "        # tokenize chroma to text tokens\n",
    "        tokenized_chroma = self.binary_chroma_tokenizer(chroma_zoomed_out)\n",
    "        chroma_string = ' '.join( tokenized_chroma['tokens'] )\n",
    "        chroma_tokens = self.roberta_tokenizer_chroma( chroma_string )\n",
    "        # make ghost files of melody and accomp pieces\n",
    "        melody_file = self.make_midi_bytes(melody_piece)\n",
    "        accomp_file = self.make_midi_bytes(accomp_piece)\n",
    "        # tokenize melody and accompaniment midi to text\n",
    "        remi_tokenized_melody = self.remi_tokenizer(melody_file)\n",
    "        melody_string = ' '.join(remi_tokenized_melody[0].tokens)\n",
    "        melody_tokens = self.roberta_tokenizer_midi(melody_string)\n",
    "        remi_tokenized_accomp = self.remi_tokenizer(accomp_file)\n",
    "        accomp_string = ' '.join(remi_tokenized_accomp[0].tokens)\n",
    "        accomp_tokens = self.roberta_tokenizer_midi(accomp_string)\n",
    "        # get text from title\n",
    "        text_description = self.midis_list[idx]\n",
    "        # tokenize text\n",
    "        text_tokens = self.roberta_tokenizer_text(text_description)\n",
    "        # return torch.LongTensor(melody_tokens['input_ids']),\n",
    "        return {\n",
    "            'melody': torch.LongTensor(melody_tokens['input_ids']),\n",
    "            'chroma': torch.LongTensor(chroma_tokens['input_ids']),\n",
    "            'text': torch.LongTensor(text_tokens['input_ids']),\n",
    "            'accomp': torch.LongTensor(accomp_tokens['input_ids'])\n",
    "        }\n",
    "    # end getitem\n",
    "\n",
    "    def chroma_from_pianoroll(self, main_piece, resolution=24):\n",
    "        # first binarize a new deep copy\n",
    "        binary_piece = deepcopy(main_piece)\n",
    "        binary_piece.binarize()\n",
    "        # make chroma\n",
    "        chroma = binary_piece.tracks[0].pianoroll[:,:12]\n",
    "        for i in range(12, 128-12, 12):\n",
    "            chroma = np.logical_or(chroma, binary_piece.tracks[0].pianoroll[:,i:(i+12)])\n",
    "        chroma[:,-6:] = np.logical_or(chroma[:,-6:], binary_piece.tracks[0].pianoroll[:,-6:])\n",
    "        # quarter chroma resolution\n",
    "        chroma_tmp = np.zeros( (1,12) )\n",
    "        chroma_zoomed_out = None\n",
    "        for i in range(chroma.shape[0]):\n",
    "            chroma_tmp += chroma[i,:]\n",
    "            if (i+1)%resolution == 0:\n",
    "                if chroma_zoomed_out is None:\n",
    "                    chroma_zoomed_out = chroma_tmp >= np.mean( chroma_tmp )\n",
    "                else:\n",
    "                    chroma_zoomed_out = np.vstack( (chroma_zoomed_out, chroma_tmp >= np.mean( chroma_tmp )) )\n",
    "        if np.sum( chroma_tmp ) > 0:\n",
    "            if chroma_zoomed_out is None:\n",
    "                chroma_zoomed_out = chroma_tmp >= np.mean( chroma_tmp )\n",
    "            else:\n",
    "                chroma_zoomed_out = np.vstack( (chroma_zoomed_out, chroma_tmp >= np.mean( chroma_tmp )) )\n",
    "        return chroma_zoomed_out\n",
    "    # end chroma_from_pianoroll\n",
    "\n",
    "    def split_melody_accompaniment(self, pypianoroll_structure):\n",
    "        melody_piece = deepcopy( pypianoroll_structure )\n",
    "        accomp_piece = deepcopy( pypianoroll_structure )\n",
    "\n",
    "        mel_pr = melody_piece.tracks[0].pianoroll\n",
    "        acc_pr = accomp_piece.tracks[0].pianoroll\n",
    "\n",
    "        pr = np.array(melody_piece.tracks[0].pianoroll)\n",
    "        running_melody = -1\n",
    "        i = 0\n",
    "        # for i in range( pr.shape[0] ):\n",
    "        while i < pr.shape[0]:\n",
    "            # check if any note\n",
    "            if np.sum(pr[i,:]) > 0:\n",
    "                # get running max\n",
    "                running_max = np.max( np.nonzero( pr[i,:] ) )\n",
    "                # check if there exists a running melody\n",
    "                if running_melody > -1:\n",
    "                    # check if running melody is continued\n",
    "                    if running_melody == running_max:\n",
    "                        # remove all lower pitches from melody\n",
    "                        mel_pr[i, :running_max] = 0\n",
    "                        # remove higher pitch from accomp\n",
    "                        acc_pr[i, running_max] = 0\n",
    "                    else:\n",
    "                        # running melody may need to change\n",
    "                        # check if new highest pitch just started\n",
    "                        if running_max > running_melody:\n",
    "                            # a new higher note has started\n",
    "                            # finish previous note that was highest until now\n",
    "                            j = 0\n",
    "                            while j+i < mel_pr.shape[0] and mel_pr[i+j, running_melody] > 0 and running_max > running_melody:\n",
    "                                mel_pr[i+j, :running_melody] = 0\n",
    "                                mel_pr[i+j, running_melody+1:running_max] = 0\n",
    "                                acc_pr[i+j, running_melody] = 0\n",
    "                                acc_pr[i+j, running_max] = 0\n",
    "                                if np.sum( pr[i+j,:] ) > 0:\n",
    "                                    running_max = np.max( np.nonzero( pr[i+j,:] ) )\n",
    "                                else:\n",
    "                                    running_melody = -1\n",
    "                                    break\n",
    "                                j += 1\n",
    "                            # start new running melody\n",
    "                            i += j-1\n",
    "                            running_melody = running_max\n",
    "                        else:\n",
    "                            # i should be > 0 since we have that running_melody > -1\n",
    "                            # a lower note has come\n",
    "                            # if has begun earlier, it should be ignored\n",
    "                            if pr[i-1, running_max] > 0:\n",
    "                                # its continuing an existing note - not part of melody\n",
    "                                mel_pr[i, :] = 0\n",
    "                                # running max should not be canceled, it remains as ghost max\n",
    "                                # until a new higher max or a fresh lower max starts\n",
    "                            else:\n",
    "                                # a new fresh lower max starts that shouldn't be ignored\n",
    "                                # start new running melody\n",
    "                                running_melody = running_max\n",
    "                                # remove all lower pitches from melody\n",
    "                                mel_pr[i, :running_max] = 0\n",
    "                                # remove higher pitch from accomp\n",
    "                                acc_pr[i, running_max] = 0\n",
    "                else:\n",
    "                    # no running melody, check max conditions\n",
    "                    # new note started - make it the running melody\n",
    "                    running_melody = running_max\n",
    "                    # remove all lower pitches from melody\n",
    "                    mel_pr[i, :running_max] = 0\n",
    "                    # remove higher pitch from accomp\n",
    "                    acc_pr[i, running_max] = 0\n",
    "                # end if\n",
    "            else:\n",
    "                # there is a gap\n",
    "                running_melody = -1\n",
    "            # end if\n",
    "            i += 1\n",
    "        # end for\n",
    "        return melody_piece, accomp_piece\n",
    "    # end split_melody_accompaniment\n",
    "\n",
    "    def make_midi_bytes(self, pianoroll_structure):\n",
    "        # initialize bytes handle\n",
    "        b_handle = io.BytesIO()\n",
    "        # write midi data to bytes handle\n",
    "        pianoroll_structure.write(b_handle)\n",
    "        # start read pointer from the beginning\n",
    "        b_handle.seek(0)\n",
    "        # create a buffered reader to read the handle\n",
    "        buffered_reader = io.BufferedReader(b_handle)\n",
    "        # create a midi object from the \"file\", i.e., buffered reader\n",
    "        midi_bytes = symusic.Score.from_midi(b_handle.getvalue())\n",
    "        # close the bytes handle\n",
    "        b_handle.close()\n",
    "        return midi_bytes\n",
    "    # end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "midifolder = '/media/datadisk/datasets/GiantMIDI-PIano/midis_v1.2/midis'\n",
    "# midifolder = '/media/datadisk/data/Giant_PIano/'\n",
    "dataset = LiveMelCATDataset(midifolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10761\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0\n",
      "Ismagilov, Timur, Spring Sketches, 2QxuHQoT5Dk.mid\n"
     ]
    }
   ],
   "source": [
    "d0 = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'melody': tensor([ 26,  70, 157,   5,  12,  26,  26,  92, 126,  36, 109,   5,  12,   5,\n",
       "           8,  26,  26,  26,  26,  26,  74, 125,  15, 124,   5,  12,   5,   8,\n",
       "          26,  93, 125,  19, 124,   5,  12,   5,   8,  26,  26,  94, 125,  21,\n",
       "         124,   5,  12,   5,   8,  26,  26,  82, 125,  16,  29,   5,   8,   5,\n",
       "          10,  26,  75, 125,  19, 124,   5,  12,   5,   8,  84, 130,  21,  20,\n",
       "           5,  12,   5,  10,  26,  87, 137,  16, 124,   5,  12,   5,   8]),\n",
       " 'chroma': tensor([25, 17,  9, 16,  5, 13,  8, 10, 14,  6, 15,  7, 12, 11, 17,  9, 16,  5,\n",
       "         13,  8, 10, 14,  6, 15,  7, 12, 11, 17,  9, 16,  5, 13,  8, 10, 14,  6,\n",
       "         15,  7, 12, 11, 17,  9, 16,  5, 13,  8, 10, 14,  6, 15,  7, 12, 11, 17,\n",
       "          9, 16,  5, 13,  8, 10, 14,  6, 15,  7, 12, 11, 17,  9, 16,  5, 13,  8,\n",
       "         10, 14,  6, 15,  7, 12, 11, 17,  9, 16,  5, 13,  8, 10, 14,  6, 15,  7,\n",
       "         12, 11, 17,  9, 16,  5, 13,  8, 10, 14,  6, 15,  7, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11, 17, 16,  8,\n",
       "         10, 14,  6, 12, 11, 17, 16,  8, 10, 14,  6, 12, 11, 17, 16,  8, 10, 14,\n",
       "          6, 12, 11, 17, 16,  8, 10, 14,  6, 12, 11, 17, 16,  8, 10, 14,  6, 12,\n",
       "         11, 17, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10, 14,  6, 12, 11,\n",
       "         17,  9, 16,  8, 10, 14,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,\n",
       "          9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,\n",
       "          8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,\n",
       "          6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17, 16,  8, 10,  6, 12, 11,\n",
       "         17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9,\n",
       "         16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8,\n",
       "         10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6,\n",
       "         12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11,\n",
       "         17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9,\n",
       "         16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8,\n",
       "         10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6,\n",
       "         12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11,\n",
       "         17,  9, 16,  8, 10,  6, 12, 11, 17,  9, 16,  8, 10,  6, 12, 11, 17,  9,\n",
       "         16,  8, 10,  6, 12, 11, 17]),\n",
       " 'text': tensor([    0,  6209, 16266,   718,  1417,     6,  2668,   710,     6,  5519,\n",
       "          4058,   594,  5559,     6,   132,  1864,  1178,   257, 37912,   139,\n",
       "           565,   245,   495,   330,     4, 16079,     2]),\n",
       " 'accomp': tensor([ 26,  70, 157,   5,  12,  26,  26,  92,  38,  24, 109,   5,  12,   5,\n",
       "           8,  52,  36, 109,   5,  12,   5,   8,  59,  36, 109,   5,  12,   5,\n",
       "           8, 111,  24, 109,   5,  12,   5,   8, 125, 101, 109,   5,  12,   5,\n",
       "           8,  87,  37,  21, 109,   5,  12,   5,   8,  40,  24, 109,   5,  12,\n",
       "           5,   8,  39,  24,  29,   5,   8,   5,  10,  55,  24, 109,   5,  12,\n",
       "           5,   8, 102,  19, 109,   5,  12,   5,   8, 105,  24, 109,   5,  12,\n",
       "           5,   8, 118,  24, 109,   5,  12,   5,   8, 121,  21, 109,   5,  12,\n",
       "           5,   8,  26,  26,  26,  26,  26,  74, 133,  30, 109,   5,  12,   5,\n",
       "           8, 105,  17,  29,   5,   8,   5,  10,  88, 111,  13,  29,   5,   8,\n",
       "           5,  10, 116,  23, 109,   5,  12,   5,   8,  59,  15,  29,   5,   8,\n",
       "           5,  10,  69,  98,  18, 109,   5,  12,   5,   8,  52,  15, 124,   5,\n",
       "          12,   5,   8, 105,  16,  95,   5,  12,   5,   8,  26,  82,  54,  17,\n",
       "         124,   5,  12,   5,   8,  59,  13,  29,   5,   8,   5,  10, 111,  13,\n",
       "          29,   5,   8,   5,  10,  93,  33,  13, 109,   5,  12,   5,   8, 105,\n",
       "          13,  29,   5,   8,   5,  10,  26,  75, 111,  16,  29,   5,   8,   5,\n",
       "          10,  66,  59,  15,  29,   5,   8,   5,  10,  89,  37,  15, 109,   5,\n",
       "          12,   5,   8,  52,  15,  29,   5,   8,   5,  10, 105,  13,  29,   5,\n",
       "           8,   5,  10,  26,  61,  59,  13,  29,   5,   8,   5,  10, 111,  16,\n",
       "          29,   5,   8,   5,  10,  94,  52,  13,  29,   5,   8,   5,  10, 105,\n",
       "          13,  29,   5,   8,   5,  10,  26,  67,  38,  16,  29,   5,   8,   5,\n",
       "          10,  59,  16,  29,   5,   8,   5,  10, 111,  13,  29,   5,   8,   5,\n",
       "          10,  88,  40,  13, 109,   5,  12,   5,   8,  52,  15,  29,   5,   8,\n",
       "           5,  10, 105,  13,  29,   5,   8,   5,  10,  81,  38,  13,  29,   5,\n",
       "           8,   5,  10,  59,  13,  29,   5,   8,   5,  10, 111,  16,  29,   5,\n",
       "           8,   5,  10,  26,  82,  52,  15,  29,   5,   8,   5,  10, 105,  15,\n",
       "          29,   5,   8,   5,  10,  76,  38,  15,  29,   5,   8,   5,  10,  59,\n",
       "          15, 109,   5,  12,   5,   8, 111,  13,  29,   5,   8,   5,  10,  26,\n",
       "          75,  52,  15, 124,   5,  12,   5,   8, 105,  15, 124,   5,  12,   5,\n",
       "           8,  84,  38,  13,  29,   5,   8,   5,  10, 111,  18,  29,   5,   8,\n",
       "           5,  10,  26,  87,  40,  15, 124,   5,  12,   5,   8, 117,  13, 124,\n",
       "           5,  12,   5,   8, 137,  16,   7,   5,   8,   5,   6, 130,  21,  11,\n",
       "           5,  14,   5,   9,  94,  38,  15, 114,   5,  12,   5,   8, 130,  16,\n",
       "         114,   5,  12,   5,   8, 111,  17, 114,   5,  12,   5,   8,  26,  92,\n",
       "          52,  17,  29,   5,   8,   5,  10, 125,  13,  29,   5,   8,   5,  10,\n",
       "         105,  17,  29,   5,   8,   5,  10, 118,  18,  29,   5,   8,   5,  10])}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0\n",
      "Ismagilov, Timur, Spring Sketches, 2QxuHQoT5Dk.mid\n",
      "idx: 1\n",
      "Gurlitt, Cornelius, Frühlingsblumen, Op.215, WD6wHfUb-kU.mid\n",
      "idx: 2\n",
      "Singelée, Jean Baptiste, Fantaisie sur des motifs de 'La sonnambula', Op.39, AcaSiJG7mkU.mid\n",
      "idx: 3\n",
      "Simpson, Daniel Léo, Kleine Klavierstücke No.9 in F major, R4z8vPF1Hto.mid\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [131] at entry 0 and [723] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m b \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:265\u001b[0m, in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_collate\u001b[39m(batch):\n\u001b[1;32m    205\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001b[39;00m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_collate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type(\u001b[43m{\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43melem\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:127\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m elem_type({key: \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem})\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;66;03m# The mapping type may not support `__init__(iterable)`.\u001b[39;00m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m {key: collate([d[key] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m batch], collate_fn_map\u001b[38;5;241m=\u001b[39mcollate_fn_map) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m elem}\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:119\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m collate_fn_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m elem_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[0;32m--> 119\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcollate_fn_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43melem_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollate_fn_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m collate_type \u001b[38;5;129;01min\u001b[39;00m collate_fn_map:\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, collate_type):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py:162\u001b[0m, in \u001b[0;36mcollate_tensor_fn\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    160\u001b[0m     storage \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_new_shared(numel, device\u001b[38;5;241m=\u001b[39melem\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    161\u001b[0m     out \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39mnew(storage)\u001b[38;5;241m.\u001b[39mresize_(\u001b[38;5;28mlen\u001b[39m(batch), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlist\u001b[39m(elem\u001b[38;5;241m.\u001b[39msize()))\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [131] at entry 0 and [723] at entry 1"
     ]
    }
   ],
   "source": [
    "b = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[ 26,  70, 157,   5,  12,  77,  98,  16,  11,   5,  12,   5,   9,  65,\n",
      "          98,  13,   7,   5,  27,   5,   6,  89,  33,  15,  11,   5,  12,   5,\n",
      "           9,  26,  67,  33,  17,   7,   5,  25,   5,   6,  72,  58,  19,   7,\n",
      "           5,  25,   5,   6,  79,  56,  19,   7,   5,  27,   5,   6,  26,  92,\n",
      "          56,  16,   7,   5,  25,   5,   6,  75,  34,  17,   7,   5,  27,   5,\n",
      "           6,  94,  58,  19,   7,   5,  25,   5,   6,  64,  33,  17,   7,   5,\n",
      "          27,   5,   6,  26,  92,  33,  18,   7,   5,  27,   5,   6,  26,  26,\n",
      "          26,  90,  51,  18, 100,   5,  12,   5,   8,  85,  32,  13,  11,   5,\n",
      "           8,   5,   9,  69,  34,  13,  11,   5,  10,   5,   9,  26,  66,  32,\n",
      "          15,  11,   5,   8,   5,   9,  69,  32,  19,   7,   5,  27,   5,   6,\n",
      "          59,  13,   7,   5,   8,   5,   6,  26,  92,  44,  19, 100,   5,  12,\n",
      "           5,   8,  26,  89,  32,  15,  20,   5,   8,   5,  10,  26,  78,  32,\n",
      "          19,  11,   5,  12,   5,   9,  59,  13,   7,   5,  25,   5,   6,  65,\n",
      "          44,  16,  95,   5,  12,   5,   8,  26,  79,  38,  18,   7,   5,   8,\n",
      "           5,   6,  26,  92,  38,  13,  20,   5,   8,   5,  10,  84,  38,  21,\n",
      "          29,   5,  12,   5,  10,  26,  84,  32,  13,   7,   5,  25,   5,   6,\n",
      "          80,  31,  13,  11,   5,  12,   5,   9,  26,  71,  39,  19,   7,   5,\n",
      "          27,   5,   6,  75,  38,  21,   7,   5,  27,   5,   6,  83,  44,  21,\n",
      "          11,   5,  12,   5,   9]])]\n"
     ]
    }
   ],
   "source": [
    "print(b)\n",
    "# print(len(b['melody']['input_ids']))\n",
    "# print(len(b['accomp']['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "243\n"
     ]
    }
   ],
   "source": [
    "print(len(b['melody'][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
